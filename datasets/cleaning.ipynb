{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Per-capita cigarette consumption (in packs). Source: Orzechowski and Walker (2005). These data are based on the total tax\n",
    "paid on sales of packs of cigarettes in a particular state divided\n",
    "by its total population.\n",
    "\n",
    "• Average retail price per pack of cigarettes (in cents). Source:\n",
    "Orzechowski and Walker (2005). Price figures include state sales\n",
    "taxes, if applicable.\n",
    "\n",
    "• Per-capita state personal income (logged). Source: Bureau of the\n",
    "Census, United States Statistical Abstract. Converted to 1997 dollars using the Consumer Price Index.\n",
    "\n",
    "• State population and percent of state population aged 15–24.\n",
    "Source: U.S. Census Bureau.\n",
    "\n",
    "• Per-capita beer consumption. Source: Beer Institute’s Brewer’s\n",
    "Almanac. Measured as the per capita consumption of malt beverages (in gallons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/smoking_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.iloc[:, 2:])\n",
    "features = scaler.transform(df.iloc[:, 2:])\n",
    "df.iloc[:, 2:] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_state = len(df.state.unique()) #number of state IDs\n",
    "n_time = len(df.year.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['state', 'year'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_smoking = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 2:] #remove state and year from features\n",
    "mask_smoking = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 2:] #remove state and year from features\n",
    "\n",
    "np.save('smoking/smoking.npy', arr_smoking)\n",
    "np.save('smoking/smoking_mask.npy', mask_smoking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39, 31, 5), '', (39, 31, 31), (39, 5), (39, 5, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, v = np.linalg.svd(arr_smoking.astype(float))\n",
    "arr_smoking.shape, '', u.shape, s.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Reunification \n",
    "- GDP per Capita (PPP, 2002 USD).\n",
    "- Investment Rate: Ratio of real domestic investment (private plus public) to real GDP. The data are reported in five-year averages.\n",
    "- Schooling: Percentage of secondary school attained in the total population aged 25 and older. The data are reported in five-year increments.\n",
    "- Industry: industry share of value added.\n",
    "- Inflation: annual percentage change in consumer prices (base year 1995).\n",
    "- Trade Openness: Export plus imports as percentage of GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 44)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/german_reunification.csv'\n",
    "df = pd.read_csv(url)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.iloc[:, 3:])\n",
    "features = scaler.transform(df.iloc[:, 3:])\n",
    "df.iloc[:, 3:] = features\n",
    "\n",
    "n_state = len(df.country.unique()) #number of units\n",
    "n_time = len(df.year.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['country', 'year'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_german = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 3:] #remove code, country, and year from features\n",
    "mask_german = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 3:] #remove code, country, and year from features\n",
    "\n",
    "np.save('germany/germany.npy', arr_german)\n",
    "np.save('germany/germany_mask.npy', mask_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basque \n",
    "- Data on terrorist activity (deaths and kidnappings) are provided by the Spanish Ministry of Interior (2002). \n",
    "- Regional data on GDP, investment, population density, and sectoral production come from Fundacio´n BBV (1999). Data on human capital for different regions have been collected by Mas et al. (1998). \n",
    "- Oil prices come from the OECD statistical compendium CD-ROM. \n",
    "- Data on stock prices, firm size (market value of outstanding shares), book equity, and dividends are routinely collected by the Madrid Stock Exchange (www.bolsamadrid.es). \n",
    "- Interest rates on one-day public debt repurchase agreements and bonds come from the Bank of Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 43)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/basque_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.iloc[:, 4:])\n",
    "features = scaler.transform(df.iloc[:, 4:])\n",
    "df.iloc[:, 4:] = features\n",
    "\n",
    "n_state = len(df.regionname.unique()) #number of units\n",
    "n_time = len(df.year.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['regionname', 'year'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_basque = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 4:] #remove code, country, and year from features\n",
    "mask_basque = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 4:] #remove code, country, and year from features\n",
    "\n",
    "np.save('basque/basque.npy', arr_basque)\n",
    "np.save('basque/basque_mask.npy', mask_basque)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail\n",
    "From https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 182)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('retail/features.csv')\n",
    "stores = pd.read_csv('retail/stores.csv')\n",
    "#features.shape, stores.shape, len(np.unique(features.Store))\n",
    "df = features.merge(stores, how='inner', on = \"Store\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "continuous_features = ['Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',\n",
    "       'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Size']\n",
    "discrete_features = ['IsHoliday', 'Type']\n",
    "state = ['Store']\n",
    "time = ['Date']\n",
    "df = df[state + time + continuous_features + discrete_features] #state, time, continuous features, discrete features\n",
    "\n",
    "scaler.fit(df.loc[:, df.columns.isin(continuous_features)])\n",
    "features = scaler.transform(df.loc[:, df.columns.isin(continuous_features)])\n",
    "df.loc[:, df.columns.isin(continuous_features)] = features\n",
    "\n",
    "n_state = len(df.Store.unique()) #number of units\n",
    "n_time = len(df.Date.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['Store', 'Date'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_retail = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 2:] # remove store and date\n",
    "mask_retail = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 2:] # remove store and date\n",
    "\n",
    "np.save('retail/retail.npy', arr_retail)\n",
    "np.save('retail/retail_mask.npy', mask_retail)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
