{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Per-capita cigarette consumption (in packs). Source: Orzechowski and Walker (2005). These data are based on the total tax\n",
    "paid on sales of packs of cigarettes in a particular state divided\n",
    "by its total population.\n",
    "\n",
    "• Average retail price per pack of cigarettes (in cents). Source:\n",
    "Orzechowski and Walker (2005). Price figures include state sales\n",
    "taxes, if applicable.\n",
    "\n",
    "• Per-capita state personal income (logged). Source: Bureau of the\n",
    "Census, United States Statistical Abstract. Converted to 1997 dollars using the Consumer Price Index.\n",
    "\n",
    "• State population and percent of state population aged 15–24.\n",
    "Source: U.S. Census Bureau.\n",
    "\n",
    "• Per-capita beer consumption. Source: Beer Institute’s Brewer’s\n",
    "Almanac. Measured as the per capita consumption of malt beverages (in gallons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/smoking_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(df.iloc[:, 2:])\n",
    "# features = scaler.transform(df.iloc[:, 2:])\n",
    "# df.iloc[:, 2:] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alabama' 'Arkansas' 'California' 'Colorado' 'Connecticut' 'Delaware'\n",
      " 'Georgia' 'Idaho' 'Illinois' 'Indiana' 'Iowa' 'Kansas' 'Kentucky'\n",
      " 'Louisiana' 'Maine' 'Minnesota' 'Mississippi' 'Missouri' 'Montana'\n",
      " 'Nebraska' 'Nevada' 'New Hampshire' 'New Mexico' 'North Carolina'\n",
      " 'North Dakota' 'Ohio' 'Oklahoma' 'Pennsylvania' 'Rhode Island'\n",
      " 'South Carolina' 'South Dakota' 'Tennessee' 'Texas' 'Utah' 'Vermont'\n",
      " 'Virginia' 'West Virginia' 'Wisconsin' 'Wyoming']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-91ab025324ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "states = df.state.unique()\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_state = len(df.state.unique()) #number of state IDs\n",
    "n_time = len(df.year.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['state', 'year'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_smoking = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 2:] #remove state and year from features\n",
    "mask_smoking = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 2:] #remove state and year from features\n",
    "\n",
    "np.save('prop99/data.npy', arr_smoking)\n",
    "np.save('prop99/mask.npy', mask_smoking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(arr_smoking.astype(float))\n",
    "arr_smoking.shape, '', u.shape, s.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Reunification \n",
    "- GDP per Capita (PPP, 2002 USD).\n",
    "- Investment Rate: Ratio of real domestic investment (private plus public) to real GDP. The data are reported in five-year averages.\n",
    "- Schooling: Percentage of secondary school attained in the total population aged 25 and older. The data are reported in five-year increments.\n",
    "- Industry: industry share of value added.\n",
    "- Inflation: annual percentage change in consumer prices (base year 1995).\n",
    "- Trade Openness: Export plus imports as percentage of GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/german_reunification.csv'\n",
    "df = pd.read_csv(url)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.iloc[:, 3:])\n",
    "features = scaler.transform(df.iloc[:, 3:])\n",
    "df.iloc[:, 3:] = features\n",
    "\n",
    "n_state = len(df.country.unique()) #number of units\n",
    "n_time = len(df.year.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['country', 'year'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_german = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 3:] #remove code, country, and year from features\n",
    "mask_german = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 3:] #remove code, country, and year from features\n",
    "\n",
    "np.save('germany/data.npy', arr_german)\n",
    "np.save('germany/mask.npy', mask_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basque \n",
    "- Data on terrorist activity (deaths and kidnappings) are provided by the Spanish Ministry of Interior (2002). \n",
    "- Regional data on GDP, investment, population density, and sectoral production come from Fundacio´n BBV (1999). Data on human capital for different regions have been collected by Mas et al. (1998). \n",
    "- Oil prices come from the OECD statistical compendium CD-ROM. \n",
    "- Data on stock prices, firm size (market value of outstanding shares), book equity, and dividends are routinely collected by the Madrid Stock Exchange (www.bolsamadrid.es). \n",
    "- Interest rates on one-day public debt repurchase agreements and bonds come from the Bank of Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 43)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/basque_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "scaler = MinMaxScaler()\n",
    "#scaler.fit(df.iloc[:, 4:])\n",
    "#features = scaler.transform(df.iloc[:, 4:])\n",
    "#df.iloc[:, 4:] = features\n",
    "df = df[df['regionname'] != 'Spain (Espana)']\n",
    "n_state = len(df.regionname.unique()) #number of units\n",
    "n_time = len(df.year.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['regionname', 'year'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_basque = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 4:] #remove code, country, and year from features\n",
    "mask_basque = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 4:] #remove code, country, and year from features\n",
    "\n",
    "np.save('basque_unscaled/data.npy', arr_basque)\n",
    "np.save('basque_unscaled/mask.npy', mask_basque)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail\n",
    "From https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "### extra features that are not included in mRSC paper ###\n",
    "\n",
    "features = pd.read_csv('retail/features.csv')\n",
    "stores = pd.read_csv('retail/stores.csv')\n",
    "#features.shape, stores.shape, len(np.unique(features.Store))\n",
    "df = features.merge(stores, how='inner', on = \"Store\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "continuous_features = ['Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',\n",
    "       'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Size']\n",
    "discrete_features = ['IsHoliday', 'Type']\n",
    "state = ['Store']\n",
    "time = ['Date']\n",
    "df = df[state + time + continuous_features + discrete_features] #state, time, continuous features, discrete features\n",
    "\n",
    "scaler.fit(df.loc[:, df.columns.isin(continuous_features)])\n",
    "features = scaler.transform(df.loc[:, df.columns.isin(continuous_features)])\n",
    "df.loc[:, df.columns.isin(continuous_features)] = features\n",
    "\n",
    "n_state = len(df.Store.unique()) #number of units\n",
    "n_time = len(df.Date.unique()) #number of time steps\n",
    "n_state, n_time\n",
    "'''\n",
    "\n",
    "train = pd.read_csv('retail/train.csv')\n",
    "#test = pd.read_csv('retail/test.csv') # weekly sales data is nan\n",
    "#df = pd.concat([train, test], join=\"outer\", sort=True)\n",
    "df = train\n",
    "\n",
    "continuous_features = ['Weekly_Sales']\n",
    "discrete_features = ['Dept']\n",
    "state = ['Store']\n",
    "time = ['Date']\n",
    "df = df[state + time + continuous_features + discrete_features] #state, time, continuous features, discrete features\n",
    "df = df.set_index(['Store', 'Dept', 'Date']).unstack(level=-2).reset_index(level=['Store', 'Date'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.iloc[:, 2:])\n",
    "features = scaler.transform(df.iloc[:, 2:])\n",
    "df.iloc[:, 2:] = features\n",
    "\n",
    "n_state = len(df.Store.unique()) #number of units\n",
    "n_time = len(df.Date.unique()) #number of time steps\n",
    "n_metrics = len(df.columns[2:])\n",
    "n_state, n_time, n_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['Store', 'Date'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_retail = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 2:] # remove store and date\n",
    "mask_retail = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 2:] # remove store and date\n",
    "\n",
    "np.save('retail/data.npy', arr_retail)\n",
    "np.save('retail/mask.npy', mask_retail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes\n",
    "From https://archive.ics.uci.edu/ml/datasets/diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>code</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>4</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>...</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3876</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3877</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3878</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3879</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3881 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "code  id        date   4        33    34  35  36     48  56  57  ...  63  64  \\\n",
       "0      1  1991-04-21 NaN  8.000000  13.0 NaN NaN  123.0 NaN NaN  ... NaN NaN   \n",
       "1      1  1991-04-22 NaN  6.333333  13.0 NaN NaN    NaN NaN NaN  ... NaN NaN   \n",
       "2      1  1991-04-23 NaN  9.000000  13.0 NaN NaN    NaN NaN NaN  ... NaN NaN   \n",
       "3      1  1991-04-24 NaN  6.333333  14.0 NaN NaN  340.0 NaN NaN  ... NaN NaN   \n",
       "4      1  1991-04-25 NaN  5.500000  14.0 NaN NaN  288.0 NaN NaN  ... NaN NaN   \n",
       "...   ..         ...  ..       ...   ...  ..  ..    ...  ..  ..  ...  ..  ..   \n",
       "3876  70  1989-05-08 NaN  1.000000   6.5 NaN NaN  145.0 NaN NaN  ... NaN NaN   \n",
       "3877  70  1989-05-09 NaN  1.000000   7.0 NaN NaN    NaN NaN NaN  ... NaN NaN   \n",
       "3878  70  1989-05-10 NaN       NaN   7.0 NaN NaN    NaN NaN NaN  ... NaN NaN   \n",
       "3879  70  1989-05-11 NaN       NaN   7.0 NaN NaN    NaN NaN NaN  ... NaN NaN   \n",
       "3880  70  1989-05-12 NaN       NaN   7.0 NaN NaN    NaN NaN NaN  ... NaN NaN   \n",
       "\n",
       "code  65  66  67  68  69  70  71  72  \n",
       "0    NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "1    NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "2    NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3    NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "4    NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "3876 NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3877 NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3878 NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3879 NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3880 NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[3881 rows x 25 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "files = glob.glob(path+\"\\diabetes\\data*\")\n",
    "\n",
    "li = []\n",
    "\n",
    "patient_id = 1\n",
    "for f in files:\n",
    "    if f == path+\"\\diabetes\\Data-Codes\":\n",
    "        break\n",
    "    data = pd.read_csv(f, delimiter ='\t', header = None, names=[\"date\", \"time\", \"code\", \"value\"], engine='python')\n",
    "    \n",
    "    #cleaning\n",
    "    data.loc[data.index[np.where(data['date'] == '06-31-1991')], 'date'] = '06-30-1991' #incorrect date\n",
    "    data.loc[data.index[np.where(data['time'] == '56:35')], 'time'] = np.nan #incorrect time\n",
    "    data.loc[data.index[np.where(data['time'] == '188:00')], 'time'] = np.nan #incorrect time\n",
    "\n",
    "    ##remove values that can't be converted to floats\n",
    "    for idx, row in data.iterrows():\n",
    "        element = data.loc[idx,'value']\n",
    "        try:\n",
    "            float(element)\n",
    "        except ValueError:\n",
    "            data.at[idx,'value'] = np.nan\n",
    "    \n",
    "    data['id'] = patient_id\n",
    "    li.append(data)\n",
    "    patient_id += 1\n",
    "        \n",
    "        \n",
    "df = pd.concat(li)\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "df = df.drop(['time'], axis=1)\n",
    "\n",
    "# pivot dataframe\n",
    "df['value'] = df['value'].astype(float)\n",
    "df = pd.pivot_table(df, index = ['id', 'date'], columns = 'code', values = 'value').reset_index()\n",
    "df\n",
    "\n",
    "date_range = pd.date_range(df.date.min(), df.date.max(), periods = (df.date.max()-df.date.min()).days+1, normalize = True)\n",
    "\n",
    "li_final = []\n",
    "\n",
    "for idx in df.id.unique():\n",
    "    df_idx = df[df['id'] == idx]\n",
    "    dic_list = []\n",
    "    for date in date_range:\n",
    "        if date not in df_idx.date.unique():\n",
    "            dic = {'id': idx, 'date': date.date()}\n",
    "            dic_list.append(dic)\n",
    "            \n",
    "    rows = pd.DataFrame.from_dict(dic_list)\n",
    "    df_idx_ = df_idx.append(rows, ignore_index = True, sort = True)\n",
    "    li_final.append(df_idx_)\n",
    "\n",
    "\n",
    "df = pd.concat(li_final)\n",
    "df.to_csv('diabetes/allData.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-92ace1d500c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontinuous_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontinuous_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontinuous_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    396\u001b[0m         X = self._validate_data(X, reset=first_pass,\n\u001b[0;32m    397\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                                 force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'm'"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "continuous_features = df.columns[2:]\n",
    "# no discrete features\n",
    "state = ['id']\n",
    "time = ['date']\n",
    "\n",
    "scaler.fit(df.loc[:, df.columns.isin(continuous_features)])\n",
    "features = scaler.transform(df.loc[:, df.columns.isin(continuous_features)])\n",
    "df.loc[:, df.columns.isin(continuous_features)] = features\n",
    "\n",
    "n_state = len(df.id.unique()) #number of units\n",
    "n_time = len(df.date.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['id', 'date'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_diab = df.values.reshape(n_state, n_time, df.shape[1])\n",
    "mask_diab = mask_df.reshape(n_state, n_time, df.shape[1])\n",
    "\n",
    "np.save('diabetes/data.npy', arr_diab)\n",
    "np.save('diabetes/mask.npy', mask_diab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asthma: CAMP Training \n",
    "The Childhood Asthma Management Program (CAMP) was a clinical trial carried out in children with asthma. The trial was designed to determine the long-term effects of 3 treatments (budesonide, nedocromil, or placebo) on pulmonary function as measured by normalized FEV1 over a 5-6.5 year period. The design of CAMP was a multicenter, masked, placebo-controlled, randomized trial. A total of 1,041 children (311 in the budesonide group, 312 in the nedocromil group and 418 in the placebo group) aged 5-12 years were enrolled between December of 1993 and September of 1995. The primary outcome of the trial was lung function as measured by the Forced Expiratory Volume at 1 second (FEV1). Secondary outcomes included: bronchial responsiveness to methacholine, need for beclomethasone due to asthma symptoms, termination of assigned treatment due to cessation of symptoms, and as Asthma morbidity (frequency and severity of asthma symptoms, frequency and magnitude of PEFR measurements less than 80% of personal best, prn use of supplemental inhaled albuterol, nocturnal awakenings, days of limited activity, and absences from school, courses of steroids). The Study also followed participants for outcomes related to mortality, long term safety, side effects, physical growth and development, psychological growth and development, individual and family functioning, and use of health care resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('asthma/camp_teach.csv')  \n",
    "#keep control (C) and ID 79 bud (A)\n",
    "df = pd.concat([df[df['id'] == 79], df[df['TG'] == 'C']])\n",
    "\n",
    "li_final = []\n",
    "for idx in df.id.unique():\n",
    "    df_idx = df[df['id'] == idx]\n",
    "    dic_list = []\n",
    "    for date in df.visitc.unique():\n",
    "        if date not in df_idx.visitc.unique():\n",
    "            dic = {'id': idx, 'visitc': date}\n",
    "            dic_list.append(dic)\n",
    "            \n",
    "    rows = pd.DataFrame.from_dict(dic_list)\n",
    "    df_idx_ = df_idx.append(rows, ignore_index = True, sort = True)\n",
    "    li_final.append(df_idx_)\n",
    "    \n",
    "df = pd.concat(li_final)\n",
    "df\n",
    "\n",
    "continuous_features = ['PREFF','age_rz', 'hemog', 'PREFEV', 'PREFVC',  'PREPF', 'POSFEV', 'POSFVC',\n",
    "                      'POSFF', 'POSPF', 'PREFEVPP', 'PREFVCPP', 'POSFEVPP', 'POSFVCPP', 'wbc', 'agehome']\n",
    "discrete_features = ['GENDER', 'ETHNIC', 'anypet', 'woodstove', 'dehumid', 'parent_smokes', 'any_smokes']\n",
    "state = ['id']\n",
    "time = ['visitc'] #choose months\n",
    "df = df[state + time + continuous_features] #state, time, continuous features, discrete features\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.loc[:, df.columns.isin(continuous_features)])\n",
    "features = scaler.transform(df.loc[:, df.columns.isin(continuous_features)])\n",
    "df.loc[:, df.columns.isin(continuous_features)] = features\n",
    "\n",
    "n_state = len(df.id.unique()) #number of units\n",
    "n_time = len(df.visitc.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitc</th>\n",
       "      <th>PREFF</th>\n",
       "      <th>age_rz</th>\n",
       "      <th>hemog</th>\n",
       "      <th>PREFEV</th>\n",
       "      <th>PREFVC</th>\n",
       "      <th>PREPF</th>\n",
       "      <th>POSFEV</th>\n",
       "      <th>POSFVC</th>\n",
       "      <th>POSFF</th>\n",
       "      <th>POSPF</th>\n",
       "      <th>PREFEVPP</th>\n",
       "      <th>PREFVCPP</th>\n",
       "      <th>POSFEVPP</th>\n",
       "      <th>POSFVCPP</th>\n",
       "      <th>wbc</th>\n",
       "      <th>agehome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.777228</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.117742</td>\n",
       "      <td>0.134289</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.504202</td>\n",
       "      <td>0.327731</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.242574</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.127731</td>\n",
       "      <td>0.119522</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.156452</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.344538</td>\n",
       "      <td>0.453704</td>\n",
       "      <td>0.289720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122689</td>\n",
       "      <td>0.132802</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.122581</td>\n",
       "      <td>0.138201</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.453782</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.289720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>12</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.126162</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.153226</td>\n",
       "      <td>0.136897</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.205607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>16</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196639</td>\n",
       "      <td>0.179283</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.211290</td>\n",
       "      <td>0.185137</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.123377</td>\n",
       "      <td>0.554622</td>\n",
       "      <td>0.403361</td>\n",
       "      <td>0.490741</td>\n",
       "      <td>0.327103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  visitc     PREFF  age_rz     hemog    PREFEV    PREFVC   PREPF  \\\n",
       "0  79       0  0.904762   0.625  0.777228  0.132773  0.112882  0.1250   \n",
       "1  79       2  0.825397   0.625       NaN  0.127731  0.119522  0.1250   \n",
       "2  79       4  0.714286   0.625       NaN  0.122689  0.132802  0.1125   \n",
       "3  79      12  0.809524   0.625       NaN  0.132773  0.126162  0.1000   \n",
       "4  79      16  0.841270   0.625       NaN  0.196639  0.179283  0.1500   \n",
       "\n",
       "     POSFEV    POSFVC     POSFF     POSPF  PREFEVPP  PREFVCPP  POSFEVPP  \\\n",
       "0  0.117742  0.134289  0.672131  0.090909  0.504202  0.327731  0.333333   \n",
       "1  0.156452  0.135593  0.901639  0.077922  0.470588  0.344538  0.453704   \n",
       "2  0.122581  0.138201  0.672131  0.103896  0.453782  0.378151  0.324074   \n",
       "3  0.153226  0.136897  0.868852  0.103896  0.420168  0.285714  0.361111   \n",
       "4  0.211290  0.185137  0.885246  0.123377  0.554622  0.403361  0.490741   \n",
       "\n",
       "   POSFVCPP       wbc   agehome  \n",
       "0  0.299065  0.242574  0.416667  \n",
       "1  0.289720       NaN       NaN  \n",
       "2  0.289720       NaN       NaN  \n",
       "3  0.205607       NaN  0.625000  \n",
       "4  0.327103       NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['id', 'visitc'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_bud = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 2:] #remove id and months\n",
    "mask_bud = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 2:]  #remove id and months\n",
    "\n",
    "np.save('asthma_bud/data.npy', arr_bud)\n",
    "np.save('asthma_bud/mask.npy', mask_bud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('asthma/camp_teach.csv')  \n",
    "#keep control (C) and ID 79 bud (A)\n",
    "df =  df[df['TG'] == 'C']\n",
    "\n",
    "li_final = []\n",
    "for idx in df.id.unique():\n",
    "    df_idx = df[df['id'] == idx]\n",
    "    dic_list = []\n",
    "    for date in df.visitc.unique():\n",
    "        if date not in df_idx.visitc.unique():\n",
    "            dic = {'id': idx, 'visitc': date}\n",
    "            dic_list.append(dic)\n",
    "            \n",
    "    rows = pd.DataFrame.from_dict(dic_list)\n",
    "    df_idx_ = df_idx.append(rows, ignore_index = True, sort = True)\n",
    "    li_final.append(df_idx_)\n",
    "    \n",
    "df = pd.concat(li_final)\n",
    "df\n",
    "\n",
    "continuous_features = ['PREFF','age_rz', 'hemog', 'PREFEV', 'PREFVC',  'PREPF', 'POSFEV', 'POSFVC',\n",
    "                      'POSFF', 'POSPF', 'PREFEVPP', 'PREFVCPP', 'POSFEVPP', 'POSFVCPP', 'wbc', 'agehome']\n",
    "discrete_features = ['GENDER', 'ETHNIC', 'anypet', 'woodstove', 'dehumid', 'parent_smokes', 'any_smokes']\n",
    "state = ['id']\n",
    "time = ['visitc'] #choose months\n",
    "df = df[state + time + continuous_features] #state, time, continuous features, discrete features\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.loc[:, df.columns.isin(continuous_features)])\n",
    "features = scaler.transform(df.loc[:, df.columns.isin(continuous_features)])\n",
    "df.loc[:, df.columns.isin(continuous_features)] = features\n",
    "\n",
    "n_state = len(df.id.unique()) #number of units\n",
    "n_time = len(df.visitc.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitc</th>\n",
       "      <th>PREFF</th>\n",
       "      <th>age_rz</th>\n",
       "      <th>hemog</th>\n",
       "      <th>PREFEV</th>\n",
       "      <th>PREFVC</th>\n",
       "      <th>PREPF</th>\n",
       "      <th>POSFEV</th>\n",
       "      <th>POSFVC</th>\n",
       "      <th>POSFF</th>\n",
       "      <th>POSPF</th>\n",
       "      <th>PREFEVPP</th>\n",
       "      <th>PREFVCPP</th>\n",
       "      <th>POSFEVPP</th>\n",
       "      <th>POSFVCPP</th>\n",
       "      <th>wbc</th>\n",
       "      <th>agehome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.808168</td>\n",
       "      <td>0.300840</td>\n",
       "      <td>0.329349</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.342894</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.554622</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.369190</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.348387</td>\n",
       "      <td>0.375489</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.596639</td>\n",
       "      <td>0.613445</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357983</td>\n",
       "      <td>0.394422</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.388710</td>\n",
       "      <td>0.395046</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.638655</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.447543</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.446774</td>\n",
       "      <td>0.452412</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.396104</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.560748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.465546</td>\n",
       "      <td>0.478088</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.481095</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.680672</td>\n",
       "      <td>0.630252</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  visitc     PREFF  age_rz     hemog    PREFEV    PREFVC   PREPF  \\\n",
       "0  10       0  0.634921   0.375  0.808168  0.300840  0.329349  0.3125   \n",
       "1  10       2  0.571429   0.375       NaN  0.317647  0.369190  0.3375   \n",
       "2  10       4  0.619048   0.375       NaN  0.357983  0.394422  0.2875   \n",
       "3  10      12  0.619048   0.375       NaN  0.411765  0.447543  0.4375   \n",
       "4  10      16  0.682540   0.375       NaN  0.465546  0.478088  0.4625   \n",
       "\n",
       "     POSFEV    POSFVC     POSFF     POSPF  PREFEVPP  PREFVCPP  POSFEVPP  \\\n",
       "0  0.338710  0.342894  0.721311  0.298701  0.588235  0.554622  0.592593   \n",
       "1  0.348387  0.375489  0.639344  0.337662  0.596639  0.613445  0.583333   \n",
       "2  0.388710  0.395046  0.704918  0.350649  0.638655  0.621849  0.629630   \n",
       "3  0.446774  0.452412  0.704918  0.396104  0.621849  0.605042  0.611111   \n",
       "4  0.483871  0.481095  0.721311  0.454545  0.680672  0.630252  0.648148   \n",
       "\n",
       "   POSFVCPP       wbc   agehome  \n",
       "0  0.523364  0.336634  0.208333  \n",
       "1  0.570093       NaN       NaN  \n",
       "2  0.570093       NaN       NaN  \n",
       "3  0.560748       NaN  0.333333  \n",
       "4  0.579439       NaN       NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 20, 16) (275, 20, 16)\n"
     ]
    }
   ],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['id', 'visitc'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_bud = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 2:] #remove id and months\n",
    "mask_bud = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 2:]  #remove id and months\n",
    "print(arr_bud.shape,mask_bud.shape)\n",
    "np.save('asthma_placebo/data.npy', arr_bud)\n",
    "np.save('asthma_placebo/mask.npy', mask_bud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 20)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('asthma/camp_teach.csv')  \n",
    "#keep control (C) and ID 82 ned (B)\n",
    "df = pd.concat([df[df['id'] == 92], df[df['TG'] == 'C']])\n",
    "\n",
    "li_final = []\n",
    "for idx in df.id.unique():\n",
    "    df_idx = df[df['id'] == idx]\n",
    "    dic_list = []\n",
    "    for date in df.visitc.unique():\n",
    "        if date not in df_idx.visitc.unique():\n",
    "            dic = {'id': idx, 'visitc': date}\n",
    "            dic_list.append(dic)\n",
    "            \n",
    "    rows = pd.DataFrame.from_dict(dic_list)\n",
    "    df_idx_ = df_idx.append(rows, ignore_index = True, sort = True)\n",
    "    li_final.append(df_idx_)\n",
    "    \n",
    "df = pd.concat(li_final)\n",
    "df\n",
    "\n",
    "continuous_features = ['age_rz', 'hemog', 'PREFEV', 'PREFVC', 'PREFF', 'PREPF', 'POSFEV', 'POSFVC',\n",
    "                      'POSFF', 'POSPF', 'PREFEVPP', 'PREFVCPP', 'POSFEVPP', 'POSFVCPP', 'wbc', 'agehome']\n",
    "discrete_features = ['GENDER', 'ETHNIC', 'anypet', 'woodstove', 'dehumid', 'parent_smokes', 'any_smokes']\n",
    "state = ['id']\n",
    "time = ['visitc'] #choose months\n",
    "df = df[state + time + continuous_features + discrete_features] #state, time, continuous features, discrete features\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.loc[:, df.columns.isin(continuous_features)])\n",
    "features = scaler.transform(df.loc[:, df.columns.isin(continuous_features)])\n",
    "df.loc[:, df.columns.isin(continuous_features)] = features\n",
    "\n",
    "n_state = len(df.id.unique()) #number of units\n",
    "n_time = len(df.visitc.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['id', 'visitc'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_ned = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 2:] #remove id and months\n",
    "mask_ned = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 2:]  #remove id and months\n",
    "\n",
    "np.save('asthma_ned/data.npy', arr_ned)\n",
    "np.save('asthma_ned/mask.npy', mask_ned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FA data \n",
    "\n",
    "df = pd.read_csv(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
