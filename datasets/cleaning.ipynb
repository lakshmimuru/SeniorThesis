{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Per-capita cigarette consumption (in packs). Source: Orzechowski and Walker (2005). These data are based on the total tax\n",
    "paid on sales of packs of cigarettes in a particular state divided\n",
    "by its total population.\n",
    "\n",
    "• Average retail price per pack of cigarettes (in cents). Source:\n",
    "Orzechowski and Walker (2005). Price figures include state sales\n",
    "taxes, if applicable.\n",
    "\n",
    "• Per-capita state personal income (logged). Source: Bureau of the\n",
    "Census, United States Statistical Abstract. Converted to 1997 dollars using the Consumer Price Index.\n",
    "\n",
    "• State population and percent of state population aged 15–24.\n",
    "Source: U.S. Census Bureau.\n",
    "\n",
    "• Per-capita beer consumption. Source: Beer Institute’s Brewer’s\n",
    "Almanac. Measured as the per capita consumption of malt beverages (in gallons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/smoking_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.iloc[:, 2:])\n",
    "features = scaler.transform(df.iloc[:, 2:])\n",
    "df.iloc[:, 2:] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state = len(df.state.unique()) #number of state IDs\n",
    "n_time = len(df.year.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['state', 'year'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_smoking = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 2:] #remove state and year from features\n",
    "mask_smoking = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 2:] #remove state and year from features\n",
    "\n",
    "np.save('smoking/data.npy', arr_smoking)\n",
    "np.save('smoking/mask.npy', mask_smoking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(arr_smoking.astype(float))\n",
    "arr_smoking.shape, '', u.shape, s.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Reunification \n",
    "- GDP per Capita (PPP, 2002 USD).\n",
    "- Investment Rate: Ratio of real domestic investment (private plus public) to real GDP. The data are reported in five-year averages.\n",
    "- Schooling: Percentage of secondary school attained in the total population aged 25 and older. The data are reported in five-year increments.\n",
    "- Industry: industry share of value added.\n",
    "- Inflation: annual percentage change in consumer prices (base year 1995).\n",
    "- Trade Openness: Export plus imports as percentage of GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/german_reunification.csv'\n",
    "df = pd.read_csv(url)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.iloc[:, 3:])\n",
    "features = scaler.transform(df.iloc[:, 3:])\n",
    "df.iloc[:, 3:] = features\n",
    "\n",
    "n_state = len(df.country.unique()) #number of units\n",
    "n_time = len(df.year.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['country', 'year'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_german = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 3:] #remove code, country, and year from features\n",
    "mask_german = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 3:] #remove code, country, and year from features\n",
    "\n",
    "np.save('germany/data.npy', arr_german)\n",
    "np.save('germany/mask.npy', mask_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basque \n",
    "- Data on terrorist activity (deaths and kidnappings) are provided by the Spanish Ministry of Interior (2002). \n",
    "- Regional data on GDP, investment, population density, and sectoral production come from Fundacio´n BBV (1999). Data on human capital for different regions have been collected by Mas et al. (1998). \n",
    "- Oil prices come from the OECD statistical compendium CD-ROM. \n",
    "- Data on stock prices, firm size (market value of outstanding shares), book equity, and dividends are routinely collected by the Madrid Stock Exchange (www.bolsamadrid.es). \n",
    "- Interest rates on one-day public debt repurchase agreements and bonds come from the Bank of Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/basque_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.iloc[:, 4:])\n",
    "features = scaler.transform(df.iloc[:, 4:])\n",
    "df.iloc[:, 4:] = features\n",
    "\n",
    "n_state = len(df.regionname.unique()) #number of units\n",
    "n_time = len(df.year.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['regionname', 'year'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_basque = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 4:] #remove code, country, and year from features\n",
    "mask_basque = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 4:] #remove code, country, and year from features\n",
    "\n",
    "np.save('basque/data.npy', arr_basque)\n",
    "np.save('basque/mask.npy', mask_basque)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail\n",
    "From https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "### extra features that are not included in mRSC paper ###\n",
    "\n",
    "features = pd.read_csv('retail/features.csv')\n",
    "stores = pd.read_csv('retail/stores.csv')\n",
    "#features.shape, stores.shape, len(np.unique(features.Store))\n",
    "df = features.merge(stores, how='inner', on = \"Store\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "continuous_features = ['Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',\n",
    "       'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Size']\n",
    "discrete_features = ['IsHoliday', 'Type']\n",
    "state = ['Store']\n",
    "time = ['Date']\n",
    "df = df[state + time + continuous_features + discrete_features] #state, time, continuous features, discrete features\n",
    "\n",
    "scaler.fit(df.loc[:, df.columns.isin(continuous_features)])\n",
    "features = scaler.transform(df.loc[:, df.columns.isin(continuous_features)])\n",
    "df.loc[:, df.columns.isin(continuous_features)] = features\n",
    "\n",
    "n_state = len(df.Store.unique()) #number of units\n",
    "n_time = len(df.Date.unique()) #number of time steps\n",
    "n_state, n_time\n",
    "'''\n",
    "\n",
    "train = pd.read_csv('retail/train.csv')\n",
    "#test = pd.read_csv('retail/test.csv') # weekly sales data is nan\n",
    "#df = pd.concat([train, test], join=\"outer\", sort=True)\n",
    "df = train\n",
    "\n",
    "continuous_features = ['Weekly_Sales']\n",
    "discrete_features = ['Dept']\n",
    "state = ['Store']\n",
    "time = ['Date']\n",
    "df = df[state + time + continuous_features + discrete_features] #state, time, continuous features, discrete features\n",
    "df = df.set_index(['Store', 'Dept', 'Date']).unstack(level=-2).reset_index(level=['Store', 'Date'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df.iloc[:, 2:])\n",
    "features = scaler.transform(df.iloc[:, 2:])\n",
    "df.iloc[:, 2:] = features\n",
    "\n",
    "n_state = len(df.Store.unique()) #number of units\n",
    "n_time = len(df.Date.unique()) #number of time steps\n",
    "n_metrics = len(df.columns[2:])\n",
    "n_state, n_time, n_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['Store', 'Date'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_retail = df.values.reshape(n_state, n_time, df.shape[1])[:, :, 2:] # remove store and date\n",
    "mask_retail = mask_df.reshape(n_state, n_time, df.shape[1])[:, :, 2:] # remove store and date\n",
    "\n",
    "np.save('retail/data.npy', arr_retail)\n",
    "np.save('retail/mask.npy', mask_retail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes\n",
    "From https://archive.ics.uci.edu/ml/datasets/diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "files = glob.glob(path+\"\\diabetes\\data*\")\n",
    "\n",
    "li = []\n",
    "\n",
    "patient_id = 1\n",
    "for f in files:\n",
    "    if f == path+\"\\diabetes\\Data-Codes\":\n",
    "        break\n",
    "    data = pd.read_csv(f, delimiter ='\t', header = None, names=[\"date\", \"time\", \"code\", \"value\"], engine='python')\n",
    "    \n",
    "    #cleaning\n",
    "    data.loc[data.index[np.where(data['date'] == '06-31-1991')], 'date'] = '06-30-1991' #incorrect date\n",
    "    data.loc[data.index[np.where(data['time'] == '56:35')], 'time'] = np.nan #incorrect time\n",
    "    data.loc[data.index[np.where(data['time'] == '188:00')], 'time'] = np.nan #incorrect time\n",
    "\n",
    "    ##remove values that can't be converted to floats\n",
    "    for idx, row in data.iterrows():\n",
    "        element = data.loc[idx,'value']\n",
    "        try:\n",
    "            float(element)\n",
    "        except ValueError:\n",
    "            data.at[idx,'value'] = np.nan\n",
    "    \n",
    "    data['id'] = patient_id\n",
    "    li.append(data)\n",
    "    patient_id += 1\n",
    "        \n",
    "        \n",
    "df = pd.concat(li)\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "df = df.drop(['time'], axis=1)\n",
    "\n",
    "# pivot dataframe\n",
    "df['value'] = df['value'].astype(float)\n",
    "df = pd.pivot_table(df, index = ['id', 'date'], columns = 'code', values = 'value').reset_index()\n",
    "\n",
    "date_range = pd.date_range(df.date.min(), df.date.max(), periods = (df.date.max()-df.date.min()).days+1, normalize = True)\n",
    "\n",
    "li_final = []\n",
    "\n",
    "for idx in df.id.unique():\n",
    "    df_idx = df[df['id'] == idx]\n",
    "    dic_list = []\n",
    "    for date in date_range:\n",
    "        if date not in df_idx.date.unique():\n",
    "            dic = {'id': idx, 'date': date.date()}\n",
    "            dic_list.append(dic)\n",
    "            \n",
    "    rows = pd.DataFrame.from_dict(dic_list)\n",
    "    df_idx_ = df_idx.append(rows, ignore_index = True, sort = True)\n",
    "    li_final.append(df_idx_)\n",
    "\n",
    "\n",
    "df = pd.concat(li_final)\n",
    "df.to_csv('diabetes/allData.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaler = MinMaxScaler()\n",
    "\n",
    "continuous_features = df.columns[2:]\n",
    "# no discrete features\n",
    "state = ['id']\n",
    "time = ['date']\n",
    "\n",
    "scaler.fit(df.loc[:, df.columns.isin(continuous_features)])\n",
    "features = scaler.transform(df.loc[:, df.columns.isin(continuous_features)])\n",
    "df.loc[:, df.columns.isin(continuous_features)] = features\n",
    "\n",
    "n_state = len(df.id.unique()) #number of units\n",
    "n_time = len(df.date.unique()) #number of time steps\n",
    "n_state, n_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [state, year, feature value]\n",
    "df = df.sort_values(by=['id', 'date'])\n",
    "mask_df = np.array(df.isna())\n",
    "df = df.fillna(0)\n",
    "\n",
    "arr_diab = df.values.reshape(n_state, n_time, df.shape[1])\n",
    "mask_diab = mask_df.reshape(n_state, n_time, df.shape[1])\n",
    "\n",
    "np.save('diabetes/data.npy', arr_diab)\n",
    "np.save('diabetes/mask.npy', mask_diab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
