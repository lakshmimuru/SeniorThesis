{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4bacc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import yaml\n",
    "sys.path.append('../models/')\n",
    "sys.path.append('../dataloader/')\n",
    "from transformer_decoder import TransformerDecoder, PositionalEncoding\n",
    "from dataloader import low_rank\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef3d9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, \n",
    "                 seed,\n",
    "                 dir_path, \n",
    "                 target_id,\n",
    "                 time_range,\n",
    "                 feature_dim,\n",
    "                 seq_len,\n",
    "                 cont_dim,\n",
    "                 lowrank_approx = False,\n",
    "                 sing_to_keep =55):\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        self.feature_dim = feature_dim\n",
    "        self.cont_dim = cont_dim\n",
    "        self.target_id = target_id\n",
    "        self.seq_len = seq_len\n",
    "        self.data_init = np.float32(np.load(dir_path+'data.npy',allow_pickle=True))\n",
    "        self.mask = np.load(dir_path+'mask.npy',allow_pickle=True).astype(bool)\n",
    "        self.data_init[self.mask] = 0\n",
    "        self.target_data = self.data_init[target_id] \n",
    "        red_data = np.delete(self.data_init,self.target_id,0)\n",
    "        if lowrank_approx:\n",
    "            red_data[:,:,:self.cont_dim] = low_rank(red_data[:,:,:self.cont_dim],sing_to_keep)\n",
    "            #fraction adjust estimator\n",
    "            data_min = np.amin(red_data.reshape(-1,self.feature_dim),0)[:self.cont_dim]\n",
    "            data_max = np.amax(red_data.reshape(-1,self.feature_dim),0)[:self.cont_dim]\n",
    "            self.data = np.insert(red_data,target_id,target_data,0)\t\n",
    "            self.data[:,:,:self.cont_dim] = (self.data[:,:,:self.cont_dim] - data_min)/(data_max - data_min)\n",
    "\n",
    "        else:\n",
    "            self.data_min = np.amin(red_data.reshape(-1,self.feature_dim),0)\n",
    "            self.data_max = np.amax(red_data.reshape(-1,self.feature_dim),0)\n",
    "            self.data = self.data_init\n",
    "            self.data[:,:,:self.cont_dim] = (self.data[:,:,:self.cont_dim] - self.data_min)/(self.data_max - self.data_min)\n",
    "        \n",
    "        self.seqs = self.data.shape[0]\n",
    "        self.time_range = time_range\n",
    "        self.time_ids = np.arange(self.time_range)\n",
    "    \n",
    "    def get_batch(self,batch_size):\n",
    "        \n",
    "        seqs = torch.zeros(batch_size,self.seq_len,self.feature_dim)\n",
    "    \n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            seq_id = np.random.randint(self.seqs)\n",
    "            interv_time = np.random.randint(self.seq_len, self.time_range)\n",
    "            seq = self.data[seq_id,interv_time - self.seq_len:interv_time]\n",
    "            seqs[i] = torch.from_numpy(seq)\n",
    "\n",
    "        seqs = seqs.to(dtype=torch.float32)\n",
    "        return seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee3579c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup dataloader\n",
    "seed  = 0\n",
    "dir_path  = '../datasets/synthetic_data_N_11_1/' \n",
    "target_id = 0\n",
    "time_range = 2000\n",
    "feature_dim = 2\n",
    "seq_len  = 256\n",
    "cont_dim = 2\n",
    "inp_feature = 2\n",
    "num_blocks = 3\n",
    "d_model = 32\n",
    "num_heads = 1\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-4\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07779097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, batch_size):\n",
    "    \n",
    "    warmup_steps = 5000\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr = lr, weight_decay = weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "                    optimizer,\n",
    "                    lambda steps: min((steps+1)/warmup_steps,1))\n",
    "    iters = 20000\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for i in range(iters):\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        seq = dataloader.get_batch(batch_size)\n",
    "        seq = seq.to(device)\n",
    "        pred = model(seq[:,:-1])\n",
    "        target = seq[:,1:].detach()\n",
    "        loss = criterion(pred,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%5000 == 0:\n",
    "            print(f'Iters: {i}',loss.item())\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1f3aa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for noise 0.5 and id 1\n",
      "Iters: 0 1.9597982168197632\n",
      "Iters: 5000 0.013714583590626717\n",
      "Iters: 10000 0.0054515814408659935\n",
      "Iters: 15000 0.0038313153199851513\n",
      "RMSE for noise 0.5 and 1 is 7.66731422052138\n",
      "Training for noise 0.5 and id 2\n",
      "Iters: 0 1.9669302701950073\n",
      "Iters: 5000 0.013386721722781658\n",
      "Iters: 10000 0.005320874508470297\n",
      "Iters: 15000 0.0036650991532951593\n",
      "RMSE for noise 0.5 and 2 is 7.582814516779606\n",
      "Training for noise 0.5 and id 3\n",
      "Iters: 0 1.9618945121765137\n",
      "Iters: 5000 0.013463648967444897\n",
      "Iters: 10000 0.005284096579998732\n",
      "Iters: 15000 0.0037042638286948204\n",
      "RMSE for noise 0.5 and 3 is 7.646450764781434\n",
      "Training for noise 0.5 and id 4\n",
      "Iters: 0 1.9768751859664917\n",
      "Iters: 5000 0.013210228644311428\n",
      "Iters: 10000 0.005325885023921728\n",
      "Iters: 15000 0.003645914141088724\n",
      "RMSE for noise 0.5 and 4 is 7.257323241551812\n",
      "Training for noise 1 and id 1\n",
      "Iters: 0 1.9539872407913208\n",
      "Iters: 5000 0.012496361508965492\n",
      "Iters: 10000 0.008739481680095196\n",
      "Iters: 15000 0.006585079710930586\n",
      "RMSE for noise 1 and 1 is 7.9467834059166425\n",
      "Training for noise 1 and id 2\n",
      "Iters: 0 1.9647303819656372\n",
      "Iters: 5000 0.011243315413594246\n",
      "Iters: 10000 0.008442615158855915\n",
      "Iters: 15000 0.005982179660350084\n",
      "RMSE for noise 1 and 2 is 7.711131529481646\n",
      "Training for noise 1 and id 3\n",
      "Iters: 0 1.9691158533096313\n",
      "Iters: 5000 0.011917585507035255\n",
      "Iters: 10000 0.009053903631865978\n",
      "Iters: 15000 0.006571130361407995\n",
      "RMSE for noise 1 and 3 is 8.587989197237803\n",
      "Training for noise 1 and id 4\n",
      "Iters: 0 1.9704054594039917\n",
      "Iters: 5000 0.010626701638102531\n",
      "Iters: 10000 0.008573068305850029\n",
      "Iters: 15000 0.006012775003910065\n",
      "RMSE for noise 1 and 4 is 8.64785653464247\n",
      "Training for noise 2 and id 1\n",
      "Iters: 0 1.9261342287063599\n",
      "Iters: 5000 0.014227520674467087\n",
      "Iters: 10000 0.012572145089507103\n",
      "Iters: 15000 0.01150081492960453\n",
      "RMSE for noise 2 and 1 is 6.46724427652192\n",
      "Training for noise 2 and id 2\n",
      "Iters: 0 1.926409125328064\n",
      "Iters: 5000 0.014321689493954182\n",
      "Iters: 10000 0.012804724276065826\n",
      "Iters: 15000 0.011318330653011799\n",
      "RMSE for noise 2 and 2 is 6.34178448861612\n",
      "Training for noise 2 and id 3\n",
      "Iters: 0 1.9281237125396729\n",
      "Iters: 5000 0.014599368907511234\n",
      "Iters: 10000 0.013088884763419628\n",
      "Iters: 15000 0.011644311249256134\n",
      "RMSE for noise 2 and 3 is 6.346883192553942\n",
      "Training for noise 2 and id 4\n",
      "Iters: 0 1.9132264852523804\n",
      "Iters: 5000 0.015214311890304089\n",
      "Iters: 10000 0.013780688866972923\n",
      "Iters: 15000 0.012212044559419155\n",
      "RMSE for noise 2 and 4 is 6.5020904164234645\n"
     ]
    }
   ],
   "source": [
    "#training for syntehtic+noise \n",
    "\n",
    "ids = [1,2,3,4]\n",
    "noise = [0.5,1,2]\n",
    "for n in noise:\n",
    "    for id in ids:\n",
    "        op_dir = f'../logs_dir/txf_baseline/noise_{n}_{id}/'\n",
    "        if not os.path.exists(op_dir):\n",
    "            os.makedirs(op_dir)\n",
    "        \n",
    "        datapath = f'../datasets/synthetic_noise{n}_{id}/'\n",
    "        dataloader = DataLoader(seed,\n",
    "                 datapath, \n",
    "                 target_id,\n",
    "                 time_range,\n",
    "                 feature_dim,\n",
    "                 seq_len,\n",
    "                 cont_dim,\n",
    "                lowrank_approx=False,\n",
    "                    )\n",
    "        model = TransformerDecoder(inp_feature, num_blocks, seq_len, d_model, num_heads)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        print(f'Training for noise {n} and id {id}')\n",
    "        model = train_model(model, dataloader, 64)\n",
    "        #save model\n",
    "        torch.save(model.state_dict(),op_dir+'model.pt')\n",
    "        #generating\n",
    "\n",
    "        interv_time = 1600\n",
    "        target_data = dataloader.target_data\n",
    "        data_min = dataloader.data_min\n",
    "        data_max = dataloader.data_max\n",
    "        target_data = (target_data - data_min )/(data_max - data_min)\n",
    "        target_data = torch.from_numpy(target_data).unsqueeze(0)\n",
    "        target_data = target_data.to(device)\n",
    "        op = model.generate(target_data[:,:interv_time],2000)\n",
    "        op = op.cpu().numpy()\n",
    "        mean = np.load(datapath+'mean1.npy')\n",
    "        test_mean = mean[0,1600:]\n",
    "        op = op*(data_max - data_min) + data_min\n",
    "        pred_mean = np.squeeze(op[:,interv_time:,0])\n",
    "        error_pred = np.sqrt(np.mean((pred_mean - test_mean )**2))\n",
    "        print(f'RMSE for noise {n} and {id} is {error_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b2b202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for donors 5 and id 1\n",
      "Iters: 0 1.9469525814056396\n",
      "Iters: 5000 0.013315978460013866\n",
      "Iters: 10000 0.009211961179971695\n",
      "Iters: 15000 0.007027772720903158\n",
      "RMSE for donors 5 and 1 is 5.151158332824707\n",
      "Training for donors 5 and id 2\n",
      "Iters: 0 1.9584866762161255\n",
      "Iters: 5000 0.013258269056677818\n",
      "Iters: 10000 0.009417972527444363\n",
      "Iters: 15000 0.007134291809052229\n",
      "RMSE for donors 5 and 2 is 5.274689197540283\n",
      "Training for donors 5 and id 3\n",
      "Iters: 0 1.9573441743850708\n",
      "Iters: 5000 0.012900927104055882\n",
      "Iters: 10000 0.008938752114772797\n",
      "Iters: 15000 0.006723702419549227\n",
      "RMSE for donors 5 and 3 is 5.455399036407471\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/synthetic_data_N_6_4/data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-96ec189b1c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdatapath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'../datasets/synthetic_data_N_{n}_{id}/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         dataloader = DataLoader(seed,\n\u001b[0m\u001b[1;32m     13\u001b[0m                  \u001b[0mdatapath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                  \u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-463f3591c6f6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, seed, dir_path, target_id, time_range, feature_dim, seq_len, cont_dim, lowrank_approx, sing_to_keep)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'data.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'mask.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_init\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/txf_design-space/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/synthetic_data_N_6_4/data.npy'"
     ]
    }
   ],
   "source": [
    "#training for syntehtic+donors \n",
    "\n",
    "ids = [1,2,3,4]\n",
    "donors = [6,11,16,21]\n",
    "for n in donors:\n",
    "    for id in ids:\n",
    "        op_dir = f'../logs_dir/txf_baseline/donors_{n}_{id}/'\n",
    "        if not os.path.exists(op_dir):\n",
    "            os.makedirs(op_dir)\n",
    "        \n",
    "        datapath = f'../datasets/synthetic_data_N_{n}_{id}/'\n",
    "        dataloader = DataLoader(seed,\n",
    "                 datapath, \n",
    "                 target_id,\n",
    "                 time_range,\n",
    "                 feature_dim,\n",
    "                 seq_len,\n",
    "                 cont_dim,\n",
    "                lowrank_approx=False,\n",
    "                    )\n",
    "        model = TransformerDecoder(inp_feature, num_blocks, seq_len, d_model, num_heads)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        print(f'Training for donors {n-1} and id {id}')\n",
    "        model = train_model(model, dataloader, 64)\n",
    "        #save model\n",
    "        torch.save(model.state_dict(),op_dir+'model.pt')\n",
    "        #generating\n",
    "\n",
    "        interv_time = 1600\n",
    "        target_data = dataloader.target_data\n",
    "        data_min = dataloader.data_min\n",
    "        data_max = dataloader.data_max\n",
    "        target_data = (target_data - data_min )/(data_max - data_min)\n",
    "        target_data = torch.from_numpy(target_data).unsqueeze(0)\n",
    "        target_data = target_data.to(device)\n",
    "        op = model.generate(target_data[:,:interv_time],2000)\n",
    "        op = op.cpu().numpy()\n",
    "        mean = np.load(datapath+'mean1.npy')\n",
    "        test_mean = mean[0,1600:]\n",
    "        op = op*(data_max - data_min) + data_min\n",
    "        pred_mean = np.squeeze(op[:,interv_time:,0])\n",
    "        error_pred = np.sqrt(np.mean((pred_mean - test_mean )**2))\n",
    "        print(f'RMSE for donors {n-1} and {id} is {error_pred}')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a11995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
